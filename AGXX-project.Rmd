---
title: "AGXX-Group"
author: "Srilakshmi", "Edward", "Aidan"
date: "2024-11-28"
output: html_document
---

Step 1: Download genomes and set up environment

Make the necessary directories for data and outputs to be stored into
```{bash}
mkdir reference_genome
mkdir originals
mkdir FastQC
mkdir bowtie_index
mkdir results
mkdir results/sam_outputs
mkdir results/bam_outputs
mkdir results/sorted_bam_outputs
mkdir featurecounts
```

Download from GenBank the FASTA (fna) file of reference genome and the gene annotation file into reference_genome
```{bash}
wget -N https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/017/085/GCA_000017085.1_ASM1708v1/GCA_000017085.1_ASM1708v1_genomic.fna.gz -O reference_genome/CP000730.fna.gz #downloading fna file for genome
wget -N https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/017/085/GCA_000017085.1_ASM1708v1/GCA_000017085.1_ASM1708v1_genomic.gtf.gz -O refernece_genome/CP000730.gtf.gz #downloading gtf - the gene annotation file for the genome
```

Download sample fastq files from www.ebi.ac.uk/arrayexpress accession number E-MTAB-7074, into the originals folder using wget
```{bash}
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/000/ERR2713020/ERR2713020_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/000/ERR2713020/ERR2713020_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/001/ERR2713021/ERR2713021_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/001/ERR2713021/ERR2713021_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/002/ERR2713022/ERR2713022_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/002/ERR2713022/ERR2713022_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/003/ERR2713023/ERR2713023_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/003/ERR2713023/ERR2713023_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/004/ERR2713024/ERR2713024_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/004/ERR2713024/ERR2713024_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/005/ERR2713025/ERR2713025_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/005/ERR2713025/ERR2713025_2.fastq.gz
```

Create a new working environment called agxx using conda on the HPC
```{bash}
srun -p msc_appbio --pty /bin/bash # Ask for resources to run the job in the msc_appbio partition
conda create -n agxx #create the environment for all the packages to be installed into
conda activate agxx #activate environement before installing packages
```

Install the necessary packages needed for alignment of the genome.
```{bash}
conda install -c bioconda fastqc
conda install bioconda::bowtie2
conda install -c bioconda samtools
conda install -c bioconda subread
```

Step 2: Pre alignment QC

QC the samples using fastqc
```{bash}
nano fastqc.sh
#Contents of the bash script:
#!/bin/bash

echo "Beginning FastQC for Samples"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="originals/"
output_dir="FastQC/"

# Begin FastQC
for sample in "${samples[@]}"; do
    echo "Running FastQC on $sample"

 # Run FastQC on both paired-end files
    fastqc -o "$output_dir" -t 4 "${input_dir}${sample}_1.fastq.gz"
    fastqc -o "$output_dir" -t 4 "${input_dir}${sample}_2.fastq.gz"
done

echo "FastQC analysis completed for all samples"

# Run the batch job
sbatch -J fastqc -p msc_appbio fastqc.sh # -p ensures the msc_appbio partition is used
#and use squeue -u knumber to see how the file is running
```

Once QC has run, transfer HTML files onto local disk using sftp
```{bash}
#On a new terminal login to sftp using sftp -i ~/.ssh/create_msc knumber@hpc.create.kcl.ac.uk

#Change directory to location of html files
cd /scratch_tmp/grp/msc_appbio/group5_tmp/FastQC

#Change directory to where the FastQC files need to be downloaded into the local drive
get *.html # ensures all html files are downloaded onto the local disk.
```

Once QC of files have been done move to alignment of the genome.

Step 3: Alignment In order to align the genome to the reference genome create the bowtie index:
```{bash}
bowtie2-build --threads 4 /scratch_tmp/grp/msc_appbio/group5_tmp/reference_genome/CP000730.fna.gz  /scratch_tmp/grp/msc_appbio/group5_tmp/bowtie_index/index
```

Create a bash file and run the alignment for all the fastq files
```{bash}
nano alignment.sh

srun -p msc_appbio --pty /bin/bash

#Contents of the bash script:
#!/bin/bash

echo "Begin Alignment"

# Array of sample IDs
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
index="bowtie_index/index"
input_dir="originals"
output_dir="results/sam_outputs"

# Align each sample
for sample in "${samples[@]}"; do
    echo "Aligning Sample $sample"
    bowtie2 -x "$index" \
            -1 "$input_dir/${sample}_1.fastq.gz" \
            -2 "$input_dir/${sample}_2.fastq.gz" \
            -S "$output_dir/${sample}.sam"
done

echo "Alignment complete"

#Submit the job for alignment
sbatch -J alignment -p msc_appbio alignment.sh
```

Ensure that the correct sam files are present and then create a bash script convert sam to bam format
```{bash}
nano sam_bam.sh

#Contents of the bash script:
#!/bin/bash

echo "Converting SAM to BAM"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="results/sam_outputs"
output_dir="results/bam_outputs"

# Convert each sample
for sample in "${samples[@]}"; do
    echo "Converting $sample"
    samtools view -b -S -o "$output_dir/${sample}.bam" "$input_dir/${sample}.sam"
done

echo "Completion of SAM to BAM"

#Submit the job for alignment
sbatch -J sam_bam -p msc_appbio sam_bam.sh
```

For ease of read, the bam file can be sorted into a sorted bam file.
```{bash}
nano sorted_bam.sh

#Contents of the bash script:
#!/bin/bash

echo "Sorting BAM files"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="results/bam_outputs"
output_dir="results/sorted_bam_outputs"

# Sort each BAM file
for sample in "${samples[@]}"; do
    echo "Sorting BAM $sample"
    samtools sort "$input_dir/${sample}.bam" -o "$output_dir/${sample}.sorted.bam"
done

echo "Sorting complete"

#Submit the job for alignment
sbatch -J sortedbam -p msc_appbio sorted_bam.sh
```

In order for Diffrential Analysis with DESeq2, feature counts in the conda subread package needs to be used to obtain a counts file.
```{bash}
#Contents of bash script:
#!/bin/bash

#Base paths
input_dir="results/sorted_bam_outputs"
output_dir="featurecounts/"
gtf_file="reference_genome/CP000730.gtf.gz"

# Run FeatureCounts
echo "Creating counts file"
featureCounts -t CDS -g gene_id -F GTF -p -a "$gtf_file" -o "$output_dir/allcounts.txt" \
    "$input_dir/ERR2713020.sorted.bam" "$input_dir/ERR2713021.sorted.bam" "$input_dir/ERR2713022.sorted.bam" \
    "$input_dir/ERR2713023.sorted.bam" "$input_dir/ERR2713024.sorted.bam" "$input_dir/ERR2713025.sorted.bam" \

echo "Counts file created"
```

Filtering and cleaning the counts file to convert into a csv file
```{bash}
sed '1d' allcounts.txt > allcounts_no_header.txt #remove the header

awk '{print $1, $7, $8, $9, $10, $11, $12}' allcounts_no_header.txt > allcounts_filtered.txt #extract columns 1 for geneid and 7-12 for sample counts.

sed -i '1s/.*/Geneid ERR2713020 ERR2713021 ERR2713022 ERR2713023 ERR2713024 ERR2713025/' allcounts_filtered.txt #rename the column names to match sample names.

sed 's/\s\+/,/g' allcounts_filtered.txt > allcounts.csv #creating a comma separated file
```
