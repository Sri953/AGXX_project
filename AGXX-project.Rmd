---
title: "AGXX-Group"
author: "Srilakshmi", "Edward", "Aidan"
date: "2024-11-28"
output: html_document
---

Step 1: Download genomes and set up environment

Make the necessary directories for data and outputs to be stored into
```{bash}
mkdir reference_genome
mkdir originals
mkdir FastQC
mkdir bowtie_index
mkdir results
mkdir results/sam_outputs
mkdir results/bam_outputs
mkdir results/sorted_bam_outputs
mkdir featurecounts
```

Download from GenBank the FASTA (fna) file of reference genome and the gene annotation file into reference_genome
```{bash}
wget -N https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/017/085/GCA_000017085.1_ASM1708v1/GCA_000017085.1_ASM1708v1_genomic.fna.gz -O reference_genome/CP000730.fna.gz #downloading fna file for genome
wget -N https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/017/085/GCA_000017085.1_ASM1708v1/GCA_000017085.1_ASM1708v1_genomic.gtf.gz -O refernece_genome/CP000730.gtf.gz #downloading gtf - the gene annotation file for the genome
```

Download sample fastq files from www.ebi.ac.uk/arrayexpress accession number E-MTAB-7074, into the originals folder using wget
```{bash}
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/000/ERR2713020/ERR2713020_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/000/ERR2713020/ERR2713020_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/001/ERR2713021/ERR2713021_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/001/ERR2713021/ERR2713021_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/002/ERR2713022/ERR2713022_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/002/ERR2713022/ERR2713022_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/003/ERR2713023/ERR2713023_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/003/ERR2713023/ERR2713023_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/004/ERR2713024/ERR2713024_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/004/ERR2713024/ERR2713024_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/005/ERR2713025/ERR2713025_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR271/005/ERR2713025/ERR2713025_2.fastq.gz
```

Create a new working environment called agxx using conda on the HPC
```{bash}
srun -p msc_appbio --pty /bin/bash # Ask for resources to run the job in the msc_appbio partition
conda create -n agxx #create the environment for all the packages to be installed into
conda activate agxx #activate environement before installing packages
```

Install the necessary packages needed for alignment of the genome.
```{bash}
conda install -c bioconda fastqc
conda install bioconda::bowtie2
conda install -c bioconda samtools
conda install -c bioconda subread
```

Step 2: Pre alignment QC

QC the samples using fastqc
```{bash}
nano fastqc.sh
#Contents of the bash script:
#!/bin/bash

echo "Beginning FastQC for Samples"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="originals/"
output_dir="FastQC/"

# Begin FastQC
for sample in "${samples[@]}"; do
    echo "Running FastQC on $sample"

 # Run FastQC on both paired-end files
    fastqc -o "$output_dir" -t 4 "${input_dir}${sample}_1.fastq.gz"
    fastqc -o "$output_dir" -t 4 "${input_dir}${sample}_2.fastq.gz"
done

echo "FastQC analysis completed for all samples"

# Run the batch job
sbatch -J fastqc -p msc_appbio fastqc.sh # -p ensures the msc_appbio partition is used
#and use squeue -u knumber to see how the file is running
```

Once QC has run, transfer HTML files onto local disk using sftp
```{bash}
#On a new terminal login to sftp using sftp -i ~/.ssh/create_msc knumber@hpc.create.kcl.ac.uk

#Change directory to location of html files
cd /scratch_tmp/grp/msc_appbio/group5_tmp/FastQC

#Change directory to where the FastQC files need to be downloaded into the local drive
get *.html # ensures all html files are downloaded onto the local disk.
```

Once QC of files have been done move to alignment of the genome.

Step 3: Alignment In order to align the genome to the reference genome create the bowtie index:
```{bash}
bowtie2-build --threads 4 /scratch_tmp/grp/msc_appbio/group5_tmp/reference_genome/CP000730.fna.gz  /scratch_tmp/grp/msc_appbio/group5_tmp/bowtie_index/index
```

Create a bash file and run the alignment for all the fastq files
```{bash}
nano alignment.sh

srun -p msc_appbio --pty /bin/bash

#Contents of the bash script:
#!/bin/bash

echo "Begin Alignment"

# Array of sample IDs
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
index="bowtie_index/index"
input_dir="originals"
output_dir="results/sam_outputs"

# Align each sample
for sample in "${samples[@]}"; do
    echo "Aligning Sample $sample"
    bowtie2 -x "$index" \
            -1 "$input_dir/${sample}_1.fastq.gz" \
            -2 "$input_dir/${sample}_2.fastq.gz" \
            -S "$output_dir/${sample}.sam"
done

echo "Alignment complete"

#Submit the job for alignment
sbatch -J alignment -p msc_appbio alignment.sh
```

Ensure that the correct sam files are present and then create a bash script convert sam to bam format
```{bash}
nano sam_bam.sh

#Contents of the bash script:
#!/bin/bash

echo "Converting SAM to BAM"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="results/sam_outputs"
output_dir="results/bam_outputs"

# Convert each sample
for sample in "${samples[@]}"; do
    echo "Converting $sample"
    samtools view -b -S -o "$output_dir/${sample}.bam" "$input_dir/${sample}.sam"
done

echo "Completion of SAM to BAM"

#Submit the job for alignment
sbatch -J sam_bam -p msc_appbio sam_bam.sh
```

For ease of read, the bam file can be sorted into a sorted bam file.
```{bash}
nano sorted_bam.sh

#Contents of the bash script:
#!/bin/bash

echo "Sorting BAM files"

# Array of sample names
samples=("ERR2713020" "ERR2713021" "ERR2713022" "ERR2713023" "ERR2713024" "ERR2713025")

# Base paths
input_dir="results/bam_outputs"
output_dir="results/sorted_bam_outputs"

# Sort each BAM file
for sample in "${samples[@]}"; do
    echo "Sorting BAM $sample"
    samtools sort "$input_dir/${sample}.bam" -o "$output_dir/${sample}.sorted.bam"
done

echo "Sorting complete"

#Submit the job for alignment
sbatch -J sortedbam -p msc_appbio sorted_bam.sh
```

In order for Diffrential Analysis with DESeq2, feature counts in the conda subread package needs to be used to obtain a counts file.
```{bash}
#Contents of bash script:
#!/bin/bash

#Base paths
input_dir="results/sorted_bam_outputs"
output_dir="featurecounts/"
gtf_file="reference_genome/CP000730.gtf.gz"

# Run FeatureCounts
echo "Creating counts file"
featureCounts -t CDS -g gene_id -F GTF -p -a "$gtf_file" -o "$output_dir/allcounts.txt" \
    "$input_dir/ERR2713020.sorted.bam" "$input_dir/ERR2713021.sorted.bam" "$input_dir/ERR2713022.sorted.bam" \
    "$input_dir/ERR2713023.sorted.bam" "$input_dir/ERR2713024.sorted.bam" "$input_dir/ERR2713025.sorted.bam" \

echo "Counts file created"
```

Filtering and cleaning the counts file to convert into a csv file
```{bash}
sed '1d' allcounts.txt > allcounts_no_header.txt #remove the header

awk '{print $1, $7, $8, $9, $10, $11, $12}' allcounts_no_header.txt > allcounts_filtered.txt #extract columns 1 for geneid and 7-12 for sample counts.

sed -i '1s/.*/Geneid ERR2713020 ERR2713021 ERR2713022 ERR2713023 ERR2713024 ERR2713025/' allcounts_filtered.txt #rename the column names to match sample names.

sed 's/\s\+/,/g' allcounts_filtered.txt > allcounts.csv #creating a comma separated file
```

STAGE 2

Once a counts file has been obtained from the alignment. The file can be imported into R for differential analysis.

First install and load the below packages
```{r}
#install.packages("DESeq2")
#install.packages("dplyr")
#install.packages("ggplot2")
library(DESeq2) #for diffrential analysis
library(dplyr) #used for certain functions
library(ggplot2) #to be able to manually plot the MAplot
```

Import the counts file obtained from feature counts after alignment.
```{r}
count <- read.csv("C:/Users/srila/AGXX_project/allcounts.csv") #downloaded in csv format

count #visualise the table (ensure it is in a dataframe format)
```

For differential analysis, a metadata file is required to label the samples. To identify this, download the sample and data relationship format file provided by the paper.
```{r}
#install.packages("readr")
#install.packages("data.table")

library(readr)
library(data.table)
sdrf_data <- read_tsv("C:/Users/srila/Downloads/E-MTAB-7074/E-MTAB-7074.sdrf.txt") #writen in tsv format

sdrf_data
#The output data indicates that the first three samples (ENA_Run: ERR2713020, ERR2713021, and ERR2713022) were treated with 4.5 Âµg/ml of AGXX, classifying them as the treatment group as described in the paper. The last three samples are therefore identified as the control group.
```

R can sometimes give an error of duplicate rows so to avoid this, remove the row names, make them unique and insert back into the data frame.
```{r}
uniq_name <- make.names(count$Geneid, unique = TRUE) #making values unique and readable by R
row.names(count) <- uniq_name #insert back into the dataframe
mat <- count #preserves original counts file
mat <- mat[, -1] #used for DESeqDataSetFromMatrix command as it requires a numeric matrix of raw counts as the input.

count #visualise
```

Setting up the metadata file and the experimental design for DESeq2
```{r}

metadata <- c("treatement", "treatement", "treatement", "control", "control", "control") 

colData <- data.frame(metadata = metadata) #ensure its a dataframe

colData #visualise

```

Create the data set object used for the analysis.
```{r}
ds <- DESeqDataSetFromMatrix(countData=mat, colData=colData, design=~metadata) 
#countData is the raw input of the data without identifiers.
#colData the dataframe object containing the metadata about the samples, keeps data organised.
#experimental design ensures the test only compares between the samples, tells DESeq2 to model differences based on colData.
ds
```

Perform the DESeq analysis
```{r}
ds <- DESeq(ds)
```

Get the results and visualise the summary
```{r}
res <- results(ds, alpha = 0.05) #deseq defaults p value to 0.1, this can be adjusted to 0.05 as specified by the paper
res <- as_tibble(res, rownames = "USA300.numbers") #rename the rownames as that of the locustags and convert as a tibble for easy analysis and visualisation.

res #visualise

summary(res)
```

R can instantly plot an MA plot using its own function.
```{r}
plotMA(ds) #plots a simple MA plot.
#We can manually plot the graph specifying our needs.
```

We can manually plot an MA plot specifying our needs. To annotate the regulons on the graph, 
Import in the supplementary table to merge in columns for Regulons according to the locus tags
```{r}
supp_table <- read.csv("~/AGXX_project/Table 1.csv") #import supplementary table

supp_table #visualises
```

Merge with left join and filter out columns for significantly induced and repressed transcripts
```{r}
supplementary_selected <- supp_table %>%
  select(USA300.numbers, Regulon, Gene.symbol) #select only the rows containing Regulon and the locus tags

res_merged <- res %>%
  left_join(supplementary_selected, by = "USA300.numbers") #merge table by USA300.numbers with a left join

res_merged

res_merged$Significant <- ifelse(res_merged$padj <= 0.05 & res_merged$log2FoldChange >= 0.6, TRUE, FALSE) #create a column for significant values 

res_merged$Repressed <- ifelse(res_merged$padj <= 0.05 & res_merged$log2FoldChange <= -0.6, TRUE, FALSE) #create a column to identify repressed values

```

Manually plot the graph
```{r}

filtered_data <- res_merged %>% filter(!is.na(Regulon))   # create filtered_data variable to filter out regulons that are NA
ggplot(filtered_data, #plot the MA plot with filtered_data
       aes(x=log2(baseMean + 1), #x axis for A_value
           y = log2FoldChange)) +  #y axis for M_value
  geom_point(aes(colour = Regulon), size = 2.5, alpha =1)+ #plot colours for significantly induced regulons.
  scale_color_manual(values = c(
    "TetR" = "darkgreen", "HypR" = "darkred", "MhqR" = "pink", "CidR" = "brown",
    "QsrR" = "orange", "CtsR" = "purple", "HrcA" = "magenta", "CymR" = "violet",
    "PerR" = "blue", "Fur" = "cyan", "CsoR" = "lightblue", "CstR" = "lightskyblue",
    "Zur" = "green"
  )) +
  geom_point(
  data = filtered_data %>% 
    filter(Significant & !(Regulon %in% c("TetR", "HypR", "MhqR", "CidR", "QsrR", "CtsR", "HrcA", "CymR", "PerR", "Fur", "CsoR", "CstR", "Zur"))),   #ensures the colour does not override regulon assigned colours
  colour = "yellow", size = 2.5, alpha = 1) +
  geom_point(
    data = filtered_data %>%  
      filter(Repressed),
    colour = "grey30", size = 2.5, alpha = 1) + #repressed transcripts coloured grey
  labs(
    x = "A-value (Log2 Base Mean)",        #labels
    y = "M-value (Log2 Fold Change)",
    colour = "Regulon",
    title = "MA plot of Diffrential Expression by Regulon"
  ) +
  scale_x_continuous(
    breaks = seq(0, 20, by = 2) #The axis ranges from 0 to 20, incrementing by 2.
  ) +
  #Adjust the theme for better appearance
  geom_hline(yintercept = 0, color = "black", linewidth = 0.5) +  # Horizontal line at y=0
  geom_vline(xintercept = 0, color = "black", linewidth = 0.5) +  # Vertical line at x=0
  scale_y_continuous(breaks = seq(-8, 12, by = 2)) + # The axis ranges from -8 to 12, incrementing by 2.
  theme_minimal() +
  theme( #aesthetic changes
    plot.title = element_text(hjust = 0.5), #position the labels and legend accordingly
    axis.title = element_text(size = 12),
    legend.position = "right" 
  ) 
```
